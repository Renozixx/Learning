{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1f523f",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset escolhido para estudo foi o Walmart Sales dataset que estuda os dados de venda de uma das maiores redes do setor varejista\n",
    " dos estados unidos, onde nele veremos os seguintes dados:\n",
    " Store: Store number\n",
    " Date: Sales week start date\n",
    " Weekly_Sales: Sales\n",
    " Holiday_Flag: Mark on the presence or absence of a holiday\n",
    " Temperature: Air temperature in the region\n",
    " Fuel_Price: Fuel cost in the region\n",
    " CPI: Consumer price index\n",
    " Unemployment: Unemployment rate\n",
    "\n",
    " Este dataset é muito maior que outros já que ele possuí a característica de analizar 45 lojas em direntes datas.\n",
    " Com essa analise é possivel identificar quais padroes afetam as escolhas dos consumidores desse tipo de loja.\n",
    "\n",
    " Portanto, Objetivo:\n",
    " Entender com base nos dados apresentados o que pode afetar nas vendas de uma loja do setor de varejo\n",
    " Metrica Principal:\n",
    " Dataset Utilizado: https://www.kaggle.com/datasets/mikhail1681/walmart-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "# from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# Leitura do dataset\n",
    "ds = pd.read_csv('Walmart_Sales.csv')\n",
    "\n",
    "# Separando as variaveis que queremos prever, e tratando nosso arquivo\n",
    "y = ds['Weekly_Sales']\n",
    "X = ds.drop('Weekly_Sales', axis=1)\n",
    "X = X.drop('Date', axis=1)\n",
    "\n",
    "# Dividindo os tipos de coluna\n",
    "coluna_numerica = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "coluna_categorica = ['Store', 'Holiday_Flag']\n",
    "\n",
    "# Aplicando One-Hot (Transforma valores \"flag\" em tabelas prontas)\n",
    "X = pd.get_dummies(X, columns=coluna_categorica, drop_first=True)\n",
    "\n",
    "# Aplicando a escala no dataset\n",
    "aply_scale = StandardScaler()\n",
    "X[coluna_numerica] = aply_scale.fit_transform(X[coluna_numerica])\n",
    "\n",
    "# Divisão de dados para teste e treino\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criação da Rede Neural\n",
    "rn = keras.Sequential([\n",
    "    # Camada de entrada\n",
    "    layers.Dense(units=512, activation='relu', input_shape=[X_treino.shape[1]]),\n",
    "    layers.Dropout(0.2),\n",
    "    # Camada Oculta\n",
    "    layers.Dense(units=256, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    # Camada de Saída\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "# compilação da rede neural\n",
    "rn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# early stop para evitar o overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# execução da rede neural\n",
    "result = rn.fit(\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    epochs=200,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "# Printando o histórico de erros\n",
    "loss_teste = rn.evaluate(X_teste, y_teste)\n",
    "print(f'{loss_teste:.2f}')\n",
    "r = loss_teste **0.5\n",
    "print(r)\n",
    "\n",
    "def imp_var(rn, X_teste, y_teste):\n",
    "    importancia = permutation_importance(\n",
    "        rn, X_teste, y_teste, n_repeats=10, random_state=42, n_jobs=1,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    sorted_importances_idx = importancia.importances_mean.argsort()\n",
    "    sorted_importances = pd.DataFrame(\n",
    "           importancia.importances[sorted_importances_idx].T,\n",
    "        columns=X_teste.columns[sorted_importances_idx],\n",
    "    )\n",
    "    print(sorted_importances)\n",
    "\n",
    "def Testar_rede(X_teste, y_teste, rn):\n",
    "    # Acessar as duas primeiras linhas do seu conjunto de teste\n",
    "    dados_para_prever = X_teste.iloc[:2]\n",
    "    objetivo= y_teste.iloc[:2]\n",
    "\n",
    "    # Fazer a previsão usando o seu modelo já treinado\n",
    "    prev = rn.predict(dados_para_prever)\n",
    "\n",
    "    for i in range(len(prev)):\n",
    "        print(f\"Resultado Alcançado: U${prev[i][0]:,.2f}\")\n",
    "        print(f\"Valor Real: U${objetivo.iloc[i]:,.2f}\")\n",
    "\n",
    "        # Calcular e exibir a diferença\n",
    "        diferenca = prev[i][0] - objetivo.iloc[i]\n",
    "        print(f\"Diferença: U${diferenca:,.2f}\")\n",
    "\n",
    "Testar_rede(X_teste, y_teste, rn)\n",
    "imp_var(rn, X_teste, y_teste)\n",
    "\n",
    "# plotagem/gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result.history['loss'], label='Erro de Treino')\n",
    "plt.plot(result.history['val_loss'], label='Erro de Validação')\n",
    "plt.title('Curva de Aprendizagem (Loss)')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Erro Quadrático Médio (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
